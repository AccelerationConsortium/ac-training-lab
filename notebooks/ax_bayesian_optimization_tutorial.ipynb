{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ax Bayesian Optimization with Prefect Human-in-the-Loop Tutorial\n",
    "\n",
    "This notebook demonstrates how to integrate Ax (Adaptive Experimentation Platform) with Prefect for human-in-the-loop Bayesian optimization workflows.\n",
    "\n",
    "## Overview\n",
    "\n",
    "- **Objective**: Optimize the Hartmann6 benchmark function\n",
    "- **Method**: Bayesian optimization with Ax\n",
    "- **Workflow**: Prefect for orchestration and human-in-the-loop\n",
    "- **Persistence**: MongoDB for checkpointing and restart capability\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run to install dependencies\n",
    "# !pip install ax-platform prefect pymongo numpy matplotlib plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional, Tuple, Any\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Conditional imports with fallbacks\n",
    "try:\n",
    "    from ax.service.ax_client import AxClient\n",
    "    from ax.utils.measurement.synthetic_functions import hartmann6\n",
    "    AX_AVAILABLE = True\n",
    "    print(\"‚úÖ Ax available\")\n",
    "except ImportError:\n",
    "    AX_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è  Ax not available - using fallback implementation\")\n",
    "\n",
    "try:\n",
    "    from prefect import flow, task, get_run_logger\n",
    "    from prefect.input import RunInput\n",
    "    PREFECT_AVAILABLE = True\n",
    "    print(\"‚úÖ Prefect available\")\n",
    "except ImportError:\n",
    "    PREFECT_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è  Prefect not available - using simple function decorators\")\n",
    "\n",
    "try:\n",
    "    from pymongo import MongoClient\n",
    "    MONGO_AVAILABLE = True\n",
    "    print(\"‚úÖ PyMongo available\")\n",
    "except ImportError:\n",
    "    MONGO_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è  PyMongo not available - using file-based checkpoints\")\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization configuration\n",
    "EXPERIMENT_NAME = \"notebook_hartmann6_demo\"\n",
    "N_ITERATIONS = 10\n",
    "MIN_CONFIDENCE_THRESHOLD = 0.7\n",
    "\n",
    "# MongoDB configuration (optional)\n",
    "MONGODB_CONNECTION_STRING = os.getenv(\"MONGODB_CONNECTION_STRING\", \"mongodb://localhost:27017/\")\n",
    "MONGODB_DATABASE = \"ax_tutorial_notebook\"\n",
    "MONGODB_COLLECTION = \"optimization_results\"\n",
    "\n",
    "print(f\"Experiment: {EXPERIMENT_NAME}\")\n",
    "print(f\"Iterations: {N_ITERATIONS}\")\n",
    "print(f\"Confidence threshold: {MIN_CONFIDENCE_THRESHOLD}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective Function\n",
    "\n",
    "We'll optimize the Hartmann6 function, a standard benchmark in Bayesian optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hartmann6_objective(parameters: Dict[str, float]) -> float:\n",
    "    \"\"\"\n",
    "    Hartmann6 synthetic function for optimization.\n",
    "    6-dimensional function with known global minimum ‚âà -3.32.\n",
    "    \"\"\"\n",
    "    if AX_AVAILABLE:\n",
    "        # Use the actual Ax implementation\n",
    "        x = np.array([parameters[f\"x{i}\"] for i in range(1, 7)])\n",
    "        return hartmann6(x)\n",
    "    else:\n",
    "        # Simplified version for demonstration\n",
    "        x = np.array([parameters[f\"x{i}\"] for i in range(1, 7)])\n",
    "        # This is a simplified approximation of Hartmann6\n",
    "        return np.sum(x**2) - 3.0 * np.exp(-np.sum(x**2))\n",
    "\n",
    "# Test the objective function\n",
    "test_params = {f\"x{i}\": 0.2 for i in range(1, 7)}\n",
    "test_result = hartmann6_objective(test_params)\n",
    "print(f\"Test evaluation: f({test_params}) = {test_result:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint System\n",
    "\n",
    "Implement a checkpoint system for saving and restoring optimization state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NotebookCheckpointHandler:\n",
    "    \"\"\"Simple checkpoint handler for notebook demonstrations.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.checkpoints = []\n",
    "    \n",
    "    def save_checkpoint(self, experiment_name: str, iteration: int, \n",
    "                       best_parameters: Dict, best_objective: float, \n",
    "                       metadata: Dict = None) -> str:\n",
    "        \"\"\"Save a checkpoint.\"\"\"\n",
    "        checkpoint = {\n",
    "            \"experiment_name\": experiment_name,\n",
    "            \"iteration\": iteration,\n",
    "            \"best_parameters\": best_parameters,\n",
    "            \"best_objective\": best_objective,\n",
    "            \"metadata\": metadata or {},\n",
    "            \"timestamp\": datetime.utcnow().isoformat()\n",
    "        }\n",
    "        self.checkpoints.append(checkpoint)\n",
    "        return f\"checkpoint_{len(self.checkpoints)}\"\n",
    "    \n",
    "    def get_latest_checkpoint(self, experiment_name: str) -> Optional[Dict]:\n",
    "        \"\"\"Get the latest checkpoint for an experiment.\"\"\"\n",
    "        matching = [cp for cp in self.checkpoints if cp[\"experiment_name\"] == experiment_name]\n",
    "        return matching[-1] if matching else None\n",
    "    \n",
    "    def list_checkpoints(self) -> List[Dict]:\n",
    "        \"\"\"List all checkpoints.\"\"\"\n",
    "        return self.checkpoints.copy()\n",
    "\n",
    "# Initialize checkpoint handler\n",
    "checkpoint_handler = NotebookCheckpointHandler()\n",
    "print(\"‚úÖ Checkpoint handler initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mock Ax Client\n",
    "\n",
    "Create a simplified version of Ax functionality for demonstration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MockAxClient:\n",
    "    \"\"\"Simplified Ax client for demonstration purposes.\"\"\"\n",
    "    \n",
    "    def __init__(self, experiment_name: str):\n",
    "        self.experiment_name = experiment_name\n",
    "        self.parameter_space = {f\"x{i}\": {\"bounds\": [0.0, 1.0]} for i in range(1, 7)}\n",
    "        self.trials = []\n",
    "        self.best_parameters = None\n",
    "        self.best_objective = float('inf')\n",
    "        \n",
    "    def get_next_trial(self) -> Tuple[Dict[str, float], int]:\n",
    "        \"\"\"Generate next trial parameters.\"\"\"\n",
    "        trial_index = len(self.trials)\n",
    "        \n",
    "        if trial_index == 0:\n",
    "            # Start with a random point\n",
    "            parameters = {f\"x{i}\": np.random.uniform(0, 1) for i in range(1, 7)}\n",
    "        else:\n",
    "            # Simple acquisition: explore around best point with some randomness\n",
    "            if self.best_parameters:\n",
    "                parameters = {}\n",
    "                for key, value in self.best_parameters.items():\n",
    "                    # Add Gaussian noise around best point\n",
    "                    noise = np.random.normal(0, 0.1)\n",
    "                    new_value = np.clip(value + noise, 0.0, 1.0)\n",
    "                    parameters[key] = new_value\n",
    "            else:\n",
    "                parameters = {f\"x{i}\": np.random.uniform(0, 1) for i in range(1, 7)}\n",
    "        \n",
    "        return parameters, trial_index\n",
    "    \n",
    "    def complete_trial(self, trial_index: int, parameters: Dict[str, float], \n",
    "                      objective_value: float):\n",
    "        \"\"\"Complete a trial with results.\"\"\"\n",
    "        trial = {\n",
    "            \"trial_index\": trial_index,\n",
    "            \"parameters\": parameters,\n",
    "            \"objective_value\": objective_value\n",
    "        }\n",
    "        self.trials.append(trial)\n",
    "        \n",
    "        # Update best if this is better\n",
    "        if objective_value < self.best_objective:\n",
    "            self.best_objective = objective_value\n",
    "            self.best_parameters = parameters.copy()\n",
    "    \n",
    "    def get_best_parameters(self) -> Tuple[Dict[str, float], float]:\n",
    "        \"\"\"Get current best parameters and objective.\"\"\"\n",
    "        if self.best_parameters is None:\n",
    "            return {f\"x{i}\": 0.5 for i in range(1, 7)}, float('inf')\n",
    "        return self.best_parameters.copy(), self.best_objective\n",
    "\n",
    "# Initialize optimization client\n",
    "if AX_AVAILABLE:\n",
    "    ax_client = AxClient()\n",
    "    ax_client.create_experiment(\n",
    "        name=EXPERIMENT_NAME,\n",
    "        parameters=[\n",
    "            {\"name\": f\"x{i}\", \"type\": \"range\", \"bounds\": [0.0, 1.0]}\n",
    "            for i in range(1, 7)\n",
    "        ],\n",
    "        objective_name=\"hartmann6\",\n",
    "        minimize=True,\n",
    "    )\n",
    "    print(\"‚úÖ Real Ax client initialized\")\n",
    "else:\n",
    "    ax_client = MockAxClient(EXPERIMENT_NAME)\n",
    "    print(\"‚úÖ Mock Ax client initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human-in-the-Loop Interface\n",
    "\n",
    "In a notebook environment, we'll use simple input prompts instead of Prefect's pause functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_human_input(iteration: int, confidence: float, \n",
    "                   best_parameters: Dict, best_objective: float,\n",
    "                   current_parameters: Dict, current_objective: float) -> Dict:\n",
    "    \"\"\"Get human input for decision making.\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"üß™ OPTIMIZATION UPDATE - Iteration {iteration}\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"üìä CURRENT BEST:\")\n",
    "    print(f\"   ‚Ä¢ Objective Value: {best_objective:.4f}\")\n",
    "    print(f\"   ‚Ä¢ Parameters: {best_parameters}\")\n",
    "    print()\n",
    "    print(f\"üéØ LATEST TRIAL:\")\n",
    "    print(f\"   ‚Ä¢ Parameters: {current_parameters}\")\n",
    "    print(f\"   ‚Ä¢ Objective: {current_objective:.4f}\")\n",
    "    print()\n",
    "    print(f\"ü§ñ ALGORITHM CONFIDENCE: {confidence:.1%}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # In a real Prefect workflow, this would be handled by pause_flow_run\n",
    "    # For notebook demo, we'll auto-continue with some randomness\n",
    "    import random\n",
    "    \n",
    "    if confidence > 0.8 or random.random() > 0.3:  # Usually continue\n",
    "        decision = {\n",
    "            \"continue\": True,\n",
    "            \"comments\": \"Auto-continuing for demo\",\n",
    "            \"confidence_override\": None\n",
    "        }\n",
    "        print(\"ü§ñ Auto-decision: CONTINUE (demo mode)\")\n",
    "    else:\n",
    "        decision = {\n",
    "            \"continue\": True,  # For demo, always continue\n",
    "            \"comments\": \"Low confidence but continuing for demo\",\n",
    "            \"confidence_override\": confidence + 0.1\n",
    "        }\n",
    "        print(\"ü§ñ Auto-decision: CONTINUE with confidence boost (demo mode)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "    return decision\n",
    "\n",
    "print(\"‚úÖ Human-in-the-loop interface ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Optimization Loop\n",
    "\n",
    "Now let's run the complete optimization with human-in-the-loop integration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_optimization_loop():\n",
    "    \"\"\"Run the main optimization loop.\"\"\"\n",
    "    \n",
    "    results = {\n",
    "        \"experiment_name\": EXPERIMENT_NAME,\n",
    "        \"iterations\": [],\n",
    "        \"best_parameters\": None,\n",
    "        \"best_objective\": float('inf'),\n",
    "        \"human_decisions\": []\n",
    "    }\n",
    "    \n",
    "    print(f\"üöÄ Starting optimization of {EXPERIMENT_NAME}\")\n",
    "    print(f\"üìä Target: Minimize Hartmann6 function (known minimum ‚âà -3.32)\")\n",
    "    print(f\"üéØ Iterations: {N_ITERATIONS}\")\n",
    "    print(f\"ü§ñ Confidence threshold: {MIN_CONFIDENCE_THRESHOLD}\")\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "    \n",
    "    for iteration in range(N_ITERATIONS):\n",
    "        try:\n",
    "            # Get next trial parameters\n",
    "            if AX_AVAILABLE:\n",
    "                parameters, trial_index = ax_client.get_next_trial()\n",
    "            else:\n",
    "                parameters, trial_index = ax_client.get_next_trial()\n",
    "            \n",
    "            print(f\"üî¨ Iteration {iteration + 1}/{N_ITERATIONS}\")\n",
    "            print(f\"   Trial {trial_index}: {parameters}\")\n",
    "            \n",
    "            # Evaluate objective function\n",
    "            objective_value = hartmann6_objective(parameters)\n",
    "            print(f\"   Result: {objective_value:.4f}\")\n",
    "            \n",
    "            # Complete the trial\n",
    "            if AX_AVAILABLE:\n",
    "                ax_client.complete_trial(trial_index=trial_index, raw_data=objective_value)\n",
    "            else:\n",
    "                ax_client.complete_trial(trial_index, parameters, objective_value)\n",
    "            \n",
    "            # Get current best\n",
    "            best_parameters, best_objective = ax_client.get_best_parameters()\n",
    "            \n",
    "            # Calculate confidence (simple heuristic)\n",
    "            confidence = min(0.95, (iteration + 1) * 0.08 + 0.1)\n",
    "            \n",
    "            # Store iteration results\n",
    "            iteration_result = {\n",
    "                \"iteration\": iteration + 1,\n",
    "                \"trial_index\": trial_index,\n",
    "                \"parameters\": parameters,\n",
    "                \"objective_value\": objective_value,\n",
    "                \"best_parameters\": best_parameters,\n",
    "                \"best_objective\": best_objective,\n",
    "                \"confidence\": confidence\n",
    "            }\n",
    "            results[\"iterations\"].append(iteration_result)\n",
    "            results[\"best_parameters\"] = best_parameters\n",
    "            results[\"best_objective\"] = best_objective\n",
    "            \n",
    "            # Save checkpoint\n",
    "            checkpoint_id = checkpoint_handler.save_checkpoint(\n",
    "                EXPERIMENT_NAME, iteration + 1, best_parameters, best_objective,\n",
    "                {\"confidence\": confidence, \"trial_objective\": objective_value}\n",
    "            )\n",
    "            \n",
    "            print(f\"   üíæ Checkpoint saved: {checkpoint_id}\")\n",
    "            print(f\"   üèÜ Current best: {best_objective:.4f}\")\n",
    "            \n",
    "            # Human-in-the-loop decision point\n",
    "            if confidence < MIN_CONFIDENCE_THRESHOLD or (iteration + 1) % 3 == 0:\n",
    "                print(f\"   ü§î Requesting human input (confidence: {confidence:.1%})\")\n",
    "                \n",
    "                human_decision = get_human_input(\n",
    "                    iteration + 1, confidence, best_parameters, best_objective,\n",
    "                    parameters, objective_value\n",
    "                )\n",
    "                \n",
    "                results[\"human_decisions\"].append({\n",
    "                    \"iteration\": iteration + 1,\n",
    "                    \"confidence\": confidence,\n",
    "                    \"decision\": human_decision\n",
    "                })\n",
    "                \n",
    "                if not human_decision[\"continue\"]:\n",
    "                    print(\"üõë Human requested to stop optimization\")\n",
    "                    break\n",
    "                    \n",
    "                if human_decision[\"confidence_override\"]:\n",
    "                    confidence = human_decision[\"confidence_override\"]\n",
    "                    print(f\"üéõÔ∏è  Confidence overridden to {confidence:.1%}\")\n",
    "            \n",
    "            print(f\"   ‚úÖ Iteration {iteration + 1} completed\\n\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error in iteration {iteration + 1}: {e}\")\n",
    "            # In a real implementation, we'd pause for human intervention\n",
    "            print(\"   Continuing despite error for demo purposes...\\n\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run the optimization\n",
    "optimization_results = run_optimization_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä OPTIMIZATION RESULTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"üéØ Experiment: {optimization_results['experiment_name']}\")\n",
    "print(f\"üî¢ Total iterations: {len(optimization_results['iterations'])}\")\n",
    "print(f\"üèÜ Best objective found: {optimization_results['best_objective']:.6f}\")\n",
    "print(f\"üìç Best parameters: {optimization_results['best_parameters']}\")\n",
    "print(f\"ü§ù Human interventions: {len(optimization_results['human_decisions'])}\")\n",
    "\n",
    "# Known global minimum for Hartmann6 is approximately -3.32237\n",
    "known_minimum = -3.32237\n",
    "gap = optimization_results['best_objective'] - known_minimum\n",
    "print(f\"üìè Gap to known global minimum: {gap:.6f}\")\n",
    "\n",
    "print(\"\\nüìà ITERATION HISTORY:\")\n",
    "for i, iteration in enumerate(optimization_results['iterations']):\n",
    "    marker = \"üéØ\" if iteration['objective_value'] == optimization_results['best_objective'] else \"  \"\n",
    "    print(f\"{marker} Iter {iteration['iteration']:2d}: obj = {iteration['objective_value']:8.4f}, \"\n",
    "          f\"best = {iteration['best_objective']:8.4f}, conf = {iteration['confidence']:.1%}\")\n",
    "\n",
    "print(\"\\nü§ù HUMAN DECISIONS:\")\n",
    "for decision in optimization_results['human_decisions']:\n",
    "    print(f\"   Iter {decision['iteration']:2d}: {decision['decision']['comments']} \"\n",
    "          f\"(confidence: {decision['confidence']:.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot optimization progress\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Extract data for plotting\n",
    "iterations = [r['iteration'] for r in optimization_results['iterations']]\n",
    "objectives = [r['objective_value'] for r in optimization_results['iterations']]\n",
    "best_objectives = [r['best_objective'] for r in optimization_results['iterations']]\n",
    "confidences = [r['confidence'] for r in optimization_results['iterations']]\n",
    "\n",
    "# Create subplots\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "# Plot 1: Objective values\n",
    "ax1.plot(iterations, objectives, 'bo-', label='Trial Objectives', alpha=0.7)\n",
    "ax1.plot(iterations, best_objectives, 'ro-', label='Best So Far', linewidth=2)\n",
    "ax1.axhline(y=known_minimum, color='g', linestyle='--', label=f'Known Global Min ({known_minimum:.3f})')\n",
    "ax1.set_xlabel('Iteration')\n",
    "ax1.set_ylabel('Objective Value')\n",
    "ax1.set_title('Bayesian Optimization Progress')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Confidence\n",
    "ax2.plot(iterations, confidences, 'go-', label='Algorithm Confidence')\n",
    "ax2.axhline(y=MIN_CONFIDENCE_THRESHOLD, color='r', linestyle='--', \n",
    "           label=f'HiTL Threshold ({MIN_CONFIDENCE_THRESHOLD:.1%})')\n",
    "ax2.set_xlabel('Iteration')\n",
    "ax2.set_ylabel('Confidence')\n",
    "ax2.set_title('Algorithm Confidence Over Time')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_ylim(0, 1)\n",
    "\n",
    "# Mark human intervention points\n",
    "hitl_iterations = [d['iteration'] for d in optimization_results['human_decisions']]\n",
    "for iter_num in hitl_iterations:\n",
    "    ax1.axvline(x=iter_num, color='purple', linestyle=':', alpha=0.7)\n",
    "    ax2.axvline(x=iter_num, color='purple', linestyle=':', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìä Purple dotted lines indicate human-in-the-loop intervention points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint Analysis\n",
    "\n",
    "Let's examine the checkpoints that were saved during optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze checkpoints\n",
    "checkpoints = checkpoint_handler.list_checkpoints()\n",
    "\n",
    "print(\"üíæ CHECKPOINT ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total checkpoints saved: {len(checkpoints)}\")\n",
    "\n",
    "if checkpoints:\n",
    "    latest = checkpoints[-1]\n",
    "    print(f\"\\nüìÑ Latest checkpoint:\")\n",
    "    print(f\"   Experiment: {latest['experiment_name']}\")\n",
    "    print(f\"   Iteration: {latest['iteration']}\")\n",
    "    print(f\"   Best objective: {latest['best_objective']:.6f}\")\n",
    "    print(f\"   Timestamp: {latest['timestamp']}\")\n",
    "    \n",
    "    print(f\"\\nüìä Checkpoint history:\")\n",
    "    for i, cp in enumerate(checkpoints):\n",
    "        print(f\"   {i+1:2d}. Iter {cp['iteration']:2d}: {cp['best_objective']:8.4f} \"\n",
    "              f\"({cp['timestamp'][:19]})\")\n",
    "\n",
    "print(\"\\nüîÑ These checkpoints can be used to resume optimization after interruptions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "This notebook demonstrated a complete Bayesian optimization workflow with:\n",
    "\n",
    "### ‚úÖ What We Accomplished\n",
    "- **Bayesian Optimization**: Used Ax (or mock implementation) to optimize Hartmann6\n",
    "- **Human-in-the-Loop**: Integrated decision points for human oversight\n",
    "- **Checkpointing**: Saved optimization state for restart capability\n",
    "- **Monitoring**: Visualized progress and algorithm confidence\n",
    "- **Error Handling**: Demonstrated robust error recovery\n",
    "\n",
    "### üöÄ Next Steps for Production Use\n",
    "\n",
    "1. **Setup Full Environment**:\n",
    "   ```bash\n",
    "   pip install ax-platform prefect pymongo\n",
    "   ```\n",
    "\n",
    "2. **Configure MongoDB**: Set up persistent storage for checkpoints\n",
    "\n",
    "3. **Deploy to Prefect**: Use the full workflow script for production\n",
    "\n",
    "4. **Customize for Your Problem**: Replace Hartmann6 with your objective function\n",
    "\n",
    "5. **Add Constraints**: Implement parameter constraints and feasibility checks\n",
    "\n",
    "### üìö Additional Resources\n",
    "- [Ax Documentation](https://ax.dev/)\n",
    "- [Prefect Docs](https://docs.prefect.io/)\n",
    "- [Full Tutorial Setup Guide](../docs/ax_tutorial_setup.md)\n",
    "- [Production Script](ax_bayesian_optimization_hitl.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results for further analysis\n",
    "import json\n",
    "\n",
    "# Save results to file\n",
    "results_file = f\"/tmp/{EXPERIMENT_NAME}_results.json\"\n",
    "with open(results_file, 'w') as f:\n",
    "    json.dump(optimization_results, f, indent=2, default=str)\n",
    "\n",
    "print(f\"üìÅ Results saved to: {results_file}\")\n",
    "print(\"\\nüéâ Tutorial completed successfully!\")\n",
    "print(\"\\nTo run the full production version:\")\n",
    "print(\"   python ax_bayesian_optimization_hitl.py\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}